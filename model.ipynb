{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Corn Plant Disease Classification with EfficientNet\n",
    "# Summary & How to Use\n",
    "\n",
    "The use of this web utlity platform is to let users of the internet upload pictures of corn plant images, have it be classified and get a determination output as to what kind of disease it shows. The platform will be UI/UX friendly for everyone of age, showing relevancy of informations about the indicated diseases. It is an integrated system of web development and AI modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "python3 -m venv --system-site-packages ./venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "source ./venv/bin/activate\n",
    "pip install --upgrade pip\n",
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "%pip install --upgrade -q Pillow\n",
    "%pip install -q tensorflow\n",
    "%pip install -q keras\n",
    "%pip install -q split-folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import keras\n",
    "import numpy as np\n",
    "import splitfolders\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_', 'Corn_(maize)___Northern_Leaf_Blight', 'Corn_(maize)___healthy']\n",
      "\n",
      "Total disease classes are: 4\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./data\"\n",
    "data_dir = base_path + \"/corn\"\n",
    "train_dir = base_path + \"/train\"\n",
    "test_dir = base_path + \"/test\"\n",
    "valid_dir = base_path + \"/val\"\n",
    "diseases = os.listdir(data_dir)\n",
    "\n",
    "# the ratio to split the data which goes into 60% training, 20% validation, 20% test\n",
    "splitfolders.ratio(data_dir, base_path, seed=1337, ratio=(0.6, 0.2, 0.2), group_prefix=None)\n",
    "\n",
    "print(diseases)\n",
    "print(\"\\nTotal disease classes are: {}\".format(len(diseases)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data gathered\n",
    "nums = {}\n",
    "for disease in diseases:\n",
    "    nums[disease] = len(os.listdir(data_dir + '/' + disease))\n",
    "\n",
    "img_per_class = pd.DataFrame(nums.values(), index=nums.keys(), columns=[\"No. of images\"])\n",
    "print(img_per_class)\n",
    "\n",
    "n_train = 0\n",
    "for val in nums.values():\n",
    "    n_train += val\n",
    "print(f\"\\nThere are {n_train} images in total for training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [n for n in range(4)]\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.bar(index, [n for n in nums.values()], width=0.3)\n",
    "plt.xlabel('Plants/Diseases')\n",
    "plt.ylabel('No of images available')\n",
    "plt.xticks(index, diseases)\n",
    "plt.title('Images per each class of plant disease')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data for Training\n",
    "\n",
    "In any machine learning project, it is critical to set up a trustworthy validation scheme, in order to properly evaluate and compare models. This is especially true if the dataset is small which is the case of this project. For a typical image classification problem, the standard approach is to take a deep CNN model (such as the most popular EffcientNet) trained on ImageNet, replace the last layer so that the output dimension equals the target's dimension, and fine tune it on the specific dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2310 images belonging to 4 classes.\n",
      "Found 769 images belonging to 4 classes.\n",
      "Found 773 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "\n",
    "# train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir, validation_split=0.2, subset=\"training\", \n",
    "#     seed=123, image_size=(img_height, img_width), batch_size=batch_size)\n",
    "\n",
    "# valid_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     data_dir, validation_split=0.2, subset=\"validation\", \n",
    "#     seed=123, image_size=(img_height, img_width), batch_size=batch_size)\n",
    "\n",
    "# class_names = train_ds.class_names\n",
    "# print(class_names)\n",
    "\n",
    "# Standardizing the data\n",
    "train_gen = ImageDataGenerator(rescale=1/255.0, validation_split=0, fill_mode=\"nearest\", rotation_range=40, horizontal_flip=True)\n",
    "valid_gen = ImageDataGenerator(rescale=1/255.0, validation_split=0)\n",
    "test_gen = ImageDataGenerator(rescale=1/255.0)\n",
    "\n",
    "train_gen\n",
    "valid_gen\n",
    "test_gen\n",
    "\n",
    "train_data = train_gen.flow_from_directory(directory=train_dir, target_size=(260, 260), \n",
    "    color_mode='rgb', batch_size=batch_size, shuffle=True, class_mode=\"categorical\")\n",
    "\n",
    "valid_data = valid_gen.flow_from_directory(directory=valid_dir, target_size=(260, 260), \n",
    "    color_mode='rgb', batch_size=batch_size, shuffle=True, class_mode=\"categorical\")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(directory=test_dir, target_size=(260, 260), \n",
    "    color_mode='rgb', batch_size=batch_size, shuffle=True, class_mode=\"categorical\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30295c5bec572e859485b1ffa5e89b8b3e2022ef6e3e739c1ac40f143a557caf"
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
